{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6c68c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing train/validation/test split\n",
      "Training samples: 6159\n",
      "Validation samples: 1063\n",
      "Test samples: 2391\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 32, 32])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Using cpu device\n",
      "ConvNeuralNetwork(\n",
      "  (conv_stack): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_stack): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=6, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.786522  [   64/ 6159]\n",
      "loss: 1.808214  [  384/ 6159]\n",
      "loss: 1.749138  [  704/ 6159]\n",
      "loss: 1.732627  [ 1024/ 6159]\n",
      "loss: 1.675914  [ 1344/ 6159]\n",
      "loss: 1.629692  [ 1664/ 6159]\n",
      "loss: 1.537391  [ 1984/ 6159]\n",
      "loss: 1.480549  [ 2304/ 6159]\n",
      "loss: 1.338340  [ 2624/ 6159]\n",
      "loss: 1.202157  [ 2944/ 6159]\n",
      "loss: 1.088512  [ 3264/ 6159]\n",
      "loss: 1.244759  [ 3584/ 6159]\n",
      "loss: 1.089892  [ 3904/ 6159]\n",
      "loss: 0.948313  [ 4224/ 6159]\n",
      "loss: 0.994839  [ 4544/ 6159]\n",
      "loss: 1.021674  [ 4864/ 6159]\n",
      "loss: 0.653983  [ 5184/ 6159]\n",
      "loss: 0.708628  [ 5504/ 6159]\n",
      "loss: 0.712020  [ 5824/ 6159]\n",
      "loss: 0.631921  [ 6144/ 6159]\n",
      "Validation Error: \n",
      " Accuracy: 67.1%, Avg loss: 0.731946 \n",
      "\n",
      "Saved best model to model.pth (Validation Accuracy: 67.1%)\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.875389  [   64/ 6159]\n",
      "loss: 0.696488  [  384/ 6159]\n",
      "loss: 0.599593  [  704/ 6159]\n",
      "loss: 0.647601  [ 1024/ 6159]\n",
      "loss: 0.627647  [ 1344/ 6159]\n",
      "loss: 0.629659  [ 1664/ 6159]\n",
      "loss: 0.536682  [ 1984/ 6159]\n",
      "loss: 0.467207  [ 2304/ 6159]\n",
      "loss: 0.623309  [ 2624/ 6159]\n",
      "loss: 0.532737  [ 2944/ 6159]\n",
      "loss: 0.495637  [ 3264/ 6159]\n",
      "loss: 0.566930  [ 3584/ 6159]\n",
      "loss: 0.364582  [ 3904/ 6159]\n",
      "loss: 0.409540  [ 4224/ 6159]\n",
      "loss: 0.404968  [ 4544/ 6159]\n",
      "loss: 0.366292  [ 4864/ 6159]\n",
      "loss: 0.352133  [ 5184/ 6159]\n",
      "loss: 0.343697  [ 5504/ 6159]\n",
      "loss: 0.229302  [ 5824/ 6159]\n",
      "loss: 0.244790  [ 6144/ 6159]\n",
      "Validation Error: \n",
      " Accuracy: 95.6%, Avg loss: 0.198573 \n",
      "\n",
      "Saved best model to model.pth (Validation Accuracy: 95.6%)\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.529923  [   64/ 6159]\n",
      "loss: 0.290031  [  384/ 6159]\n",
      "loss: 0.271785  [  704/ 6159]\n",
      "loss: 0.198395  [ 1024/ 6159]\n",
      "loss: 0.243601  [ 1344/ 6159]\n",
      "loss: 0.190269  [ 1664/ 6159]\n",
      "loss: 0.272685  [ 1984/ 6159]\n",
      "loss: 0.246130  [ 2304/ 6159]\n",
      "loss: 0.305362  [ 2624/ 6159]\n",
      "loss: 0.255931  [ 2944/ 6159]\n",
      "loss: 0.135361  [ 3264/ 6159]\n",
      "loss: 0.294837  [ 3584/ 6159]\n",
      "loss: 0.232061  [ 3904/ 6159]\n",
      "loss: 0.245592  [ 4224/ 6159]\n",
      "loss: 0.307514  [ 4544/ 6159]\n",
      "loss: 0.170520  [ 4864/ 6159]\n",
      "loss: 0.234100  [ 5184/ 6159]\n",
      "loss: 0.286436  [ 5504/ 6159]\n",
      "loss: 0.183264  [ 5824/ 6159]\n",
      "loss: 0.114630  [ 6144/ 6159]\n",
      "Validation Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.122819 \n",
      "\n",
      "Saved best model to model.pth (Validation Accuracy: 97.0%)\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.249917  [   64/ 6159]\n",
      "loss: 0.170655  [  384/ 6159]\n",
      "loss: 0.189395  [  704/ 6159]\n",
      "loss: 0.137109  [ 1024/ 6159]\n",
      "loss: 0.154158  [ 1344/ 6159]\n",
      "loss: 0.074388  [ 1664/ 6159]\n",
      "loss: 0.234460  [ 1984/ 6159]\n",
      "loss: 0.154276  [ 2304/ 6159]\n",
      "loss: 0.158833  [ 2624/ 6159]\n",
      "loss: 0.083084  [ 2944/ 6159]\n",
      "loss: 0.065259  [ 3264/ 6159]\n",
      "loss: 0.095116  [ 3584/ 6159]\n",
      "loss: 0.107399  [ 3904/ 6159]\n",
      "loss: 0.237406  [ 4224/ 6159]\n",
      "loss: 0.306000  [ 4544/ 6159]\n",
      "loss: 0.143111  [ 4864/ 6159]\n",
      "loss: 0.107249  [ 5184/ 6159]\n",
      "loss: 0.170057  [ 5504/ 6159]\n",
      "loss: 0.184110  [ 5824/ 6159]\n",
      "loss: 0.083625  [ 6144/ 6159]\n",
      "Validation Error: \n",
      " Accuracy: 99.6%, Avg loss: 0.054266 \n",
      "\n",
      "Saved best model to model.pth (Validation Accuracy: 99.6%)\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.191259  [   64/ 6159]\n",
      "loss: 0.102917  [  384/ 6159]\n",
      "loss: 0.110022  [  704/ 6159]\n",
      "loss: 0.135989  [ 1024/ 6159]\n",
      "loss: 0.064106  [ 1344/ 6159]\n",
      "loss: 0.100609  [ 1664/ 6159]\n",
      "loss: 0.067394  [ 1984/ 6159]\n",
      "loss: 0.201801  [ 2304/ 6159]\n",
      "loss: 0.106068  [ 2624/ 6159]\n",
      "loss: 0.103280  [ 2944/ 6159]\n",
      "loss: 0.112021  [ 3264/ 6159]\n",
      "loss: 0.072534  [ 3584/ 6159]\n",
      "loss: 0.106589  [ 3904/ 6159]\n",
      "loss: 0.059843  [ 4224/ 6159]\n",
      "loss: 0.058427  [ 4544/ 6159]\n",
      "loss: 0.096970  [ 4864/ 6159]\n",
      "loss: 0.160744  [ 5184/ 6159]\n",
      "loss: 0.049622  [ 5504/ 6159]\n",
      "loss: 0.136119  [ 5824/ 6159]\n",
      "loss: 0.073335  [ 6144/ 6159]\n",
      "Validation Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.029476 \n",
      "\n",
      "Saved best model to model.pth (Validation Accuracy: 99.8%)\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.057453  [   64/ 6159]\n",
      "loss: 0.121409  [  384/ 6159]\n",
      "loss: 0.212152  [  704/ 6159]\n",
      "loss: 0.065567  [ 1024/ 6159]\n",
      "loss: 0.116708  [ 1344/ 6159]\n",
      "loss: 0.052923  [ 1664/ 6159]\n",
      "loss: 0.054851  [ 1984/ 6159]\n",
      "loss: 0.082688  [ 2304/ 6159]\n",
      "loss: 0.071196  [ 2624/ 6159]\n",
      "loss: 0.066011  [ 2944/ 6159]\n",
      "loss: 0.039510  [ 3264/ 6159]\n",
      "loss: 0.091585  [ 3584/ 6159]\n",
      "loss: 0.050787  [ 3904/ 6159]\n",
      "loss: 0.048057  [ 4224/ 6159]\n",
      "loss: 0.026448  [ 4544/ 6159]\n",
      "loss: 0.118191  [ 4864/ 6159]\n",
      "loss: 0.107905  [ 5184/ 6159]\n",
      "loss: 0.050021  [ 5504/ 6159]\n",
      "loss: 0.076949  [ 5824/ 6159]\n",
      "loss: 0.086692  [ 6144/ 6159]\n",
      "Validation Error: \n",
      " Accuracy: 99.6%, Avg loss: 0.027682 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.048318  [   64/ 6159]\n",
      "loss: 0.026478  [  384/ 6159]\n",
      "loss: 0.074769  [  704/ 6159]\n",
      "loss: 0.051441  [ 1024/ 6159]\n",
      "loss: 0.068444  [ 1344/ 6159]\n",
      "loss: 0.034848  [ 1664/ 6159]\n",
      "loss: 0.032915  [ 1984/ 6159]\n",
      "loss: 0.058866  [ 2304/ 6159]\n",
      "loss: 0.032857  [ 2624/ 6159]\n",
      "loss: 0.060982  [ 2944/ 6159]\n",
      "loss: 0.089877  [ 3264/ 6159]\n",
      "loss: 0.098768  [ 3584/ 6159]\n",
      "loss: 0.136651  [ 3904/ 6159]\n",
      "loss: 0.050562  [ 4224/ 6159]\n",
      "loss: 0.032458  [ 4544/ 6159]\n",
      "loss: 0.066633  [ 4864/ 6159]\n",
      "loss: 0.100909  [ 5184/ 6159]\n",
      "loss: 0.106718  [ 5504/ 6159]\n",
      "loss: 0.073801  [ 5824/ 6159]\n",
      "loss: 0.025125  [ 6144/ 6159]\n",
      "Validation Error: \n",
      " Accuracy: 98.6%, Avg loss: 0.055907 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.187652  [   64/ 6159]\n",
      "loss: 0.103012  [  384/ 6159]\n",
      "loss: 0.135562  [  704/ 6159]\n",
      "loss: 0.217839  [ 1024/ 6159]\n",
      "loss: 0.566778  [ 1344/ 6159]\n",
      "loss: 0.215814  [ 1664/ 6159]\n",
      "loss: 0.131175  [ 1984/ 6159]\n",
      "loss: 0.246955  [ 2304/ 6159]\n",
      "loss: 0.106121  [ 2624/ 6159]\n",
      "loss: 0.027124  [ 2944/ 6159]\n",
      "loss: 0.046559  [ 3264/ 6159]\n",
      "loss: 0.081137  [ 3584/ 6159]\n",
      "loss: 0.031864  [ 3904/ 6159]\n",
      "loss: 0.023098  [ 4224/ 6159]\n",
      "loss: 0.035330  [ 4544/ 6159]\n",
      "loss: 0.029959  [ 4864/ 6159]\n",
      "loss: 0.047895  [ 5184/ 6159]\n",
      "loss: 0.035955  [ 5504/ 6159]\n",
      "loss: 0.040185  [ 5824/ 6159]\n",
      "loss: 0.034162  [ 6144/ 6159]\n",
      "Validation Error: \n",
      " Accuracy: 99.7%, Avg loss: 0.022677 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.072990  [   64/ 6159]\n",
      "loss: 0.032143  [  384/ 6159]\n",
      "loss: 0.015623  [  704/ 6159]\n",
      "loss: 0.026394  [ 1024/ 6159]\n",
      "loss: 0.031276  [ 1344/ 6159]\n",
      "loss: 0.024350  [ 1664/ 6159]\n",
      "loss: 0.025827  [ 1984/ 6159]\n",
      "loss: 0.057253  [ 2304/ 6159]\n",
      "loss: 0.047774  [ 2624/ 6159]\n",
      "loss: 0.021260  [ 2944/ 6159]\n",
      "loss: 0.062793  [ 3264/ 6159]\n",
      "loss: 0.097234  [ 3584/ 6159]\n",
      "loss: 0.018965  [ 3904/ 6159]\n",
      "loss: 0.012772  [ 4224/ 6159]\n",
      "loss: 0.069770  [ 4544/ 6159]\n",
      "loss: 0.032691  [ 4864/ 6159]\n",
      "loss: 0.045226  [ 5184/ 6159]\n",
      "loss: 0.011196  [ 5504/ 6159]\n",
      "loss: 0.041415  [ 5824/ 6159]\n",
      "loss: 0.082113  [ 6144/ 6159]\n",
      "Validation Error: \n",
      " Accuracy: 99.7%, Avg loss: 0.012313 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.010592  [   64/ 6159]\n",
      "loss: 0.053990  [  384/ 6159]\n",
      "loss: 0.032342  [  704/ 6159]\n",
      "loss: 0.025039  [ 1024/ 6159]\n",
      "loss: 0.027004  [ 1344/ 6159]\n",
      "loss: 0.106241  [ 1664/ 6159]\n",
      "loss: 0.026669  [ 1984/ 6159]\n",
      "loss: 0.036733  [ 2304/ 6159]\n",
      "loss: 0.032929  [ 2624/ 6159]\n",
      "loss: 0.037872  [ 2944/ 6159]\n",
      "loss: 0.007981  [ 3264/ 6159]\n",
      "loss: 0.044651  [ 3584/ 6159]\n",
      "loss: 0.006344  [ 3904/ 6159]\n",
      "loss: 0.031757  [ 4224/ 6159]\n",
      "loss: 0.017864  [ 4544/ 6159]\n",
      "loss: 0.008167  [ 4864/ 6159]\n",
      "loss: 0.014064  [ 5184/ 6159]\n",
      "loss: 0.012891  [ 5504/ 6159]\n",
      "loss: 0.010359  [ 5824/ 6159]\n",
      "loss: 0.027727  [ 6144/ 6159]\n",
      "Validation Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.013220 \n",
      "\n",
      "Early stopping triggered\n",
      "Training complete!\n",
      "Evaluating on test set:\n",
      "Test Error: \n",
      " Accuracy: 99.9%, Avg loss: 0.029009 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.998745294855709"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Define dataset paths and parameters\n",
    "source_dir = \"captured_dataset\"\n",
    "train_ratio = 0.64  # 64% for train\n",
    "val_ratio = 0.16   # 16% for validation (total train+val = 80%)\n",
    "test_ratio = 0.20  # 20% for test\n",
    "batch_size = 64\n",
    "num_epochs = 20\n",
    "model_path = \"model.pth\"\n",
    "\n",
    "# Create train/validation/test directories if they don't exist\n",
    "train_dir = os.path.join(source_dir, 'train')\n",
    "val_dir = os.path.join(source_dir, 'validation')\n",
    "test_dir = os.path.join(source_dir, 'test')\n",
    "\n",
    "# Split dataset into train/validation/test if not already done\n",
    "if not os.path.exists(train_dir) or not os.path.exists(val_dir) or not os.path.exists(test_dir):\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(val_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "    for class_name in os.listdir(source_dir):\n",
    "        class_dir = os.path.join(source_dir, class_name)\n",
    "        if not os.path.isdir(class_dir) or class_name in ['train', 'validation', 'test']:\n",
    "            continue\n",
    "\n",
    "        os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)\n",
    "        os.makedirs(os.path.join(val_dir, class_name), exist_ok=True)\n",
    "        os.makedirs(os.path.join(test_dir, class_name), exist_ok=True)\n",
    "\n",
    "        files = [f for f in os.listdir(class_dir) if os.path.isfile(os.path.join(class_dir, f))]\n",
    "        if not files:\n",
    "            print(f\"Warning: No files in {class_dir}\")\n",
    "            continue\n",
    "\n",
    "        random.shuffle(files)\n",
    "        num_files = len(files)\n",
    "        num_train = int(num_files * train_ratio)\n",
    "        num_val = int(num_files * val_ratio)\n",
    "\n",
    "        # Split files\n",
    "        train_files = files[:num_train]\n",
    "        val_files = files[num_train:num_train + num_val]\n",
    "        test_files = files[num_train + num_val:]  # Remaining 20% for test\n",
    "\n",
    "        # Copy to respective directories\n",
    "        for f in train_files:\n",
    "            shutil.copy2(os.path.join(class_dir, f), os.path.join(train_dir, class_name, f))\n",
    "        for f in val_files:\n",
    "            shutil.copy2(os.path.join(class_dir, f), os.path.join(val_dir, class_name, f))\n",
    "        for f in test_files:\n",
    "            shutil.copy2(os.path.join(class_dir, f), os.path.join(test_dir, class_name, f))\n",
    "\n",
    "    print(f\"Dataset split complete: Train={train_dir}, Validation={val_dir}, Test={test_dir}\")\n",
    "else:\n",
    "    print(\"Using existing train/validation/test split\")\n",
    "\n",
    "# Define training transformations with augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.Grayscale(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomAffine(0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Define validation/test transformations (no augmentation)\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "try:\n",
    "    training_data = datasets.ImageFolder(root=train_dir, transform=train_transform)\n",
    "    validation_data = datasets.ImageFolder(root=val_dir, transform=val_test_transform)\n",
    "    test_data = datasets.ImageFolder(root=test_dir, transform=val_test_transform)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading datasets: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Create data loaders\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(validation_data, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Check dataset structure\n",
    "print(f\"Training samples: {len(training_data)}\")\n",
    "print(f\"Validation samples: {len(validation_data)}\")\n",
    "print(f\"Test samples: {len(test_data)}\")\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break\n",
    "\n",
    "# Get device\n",
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available() else\n",
    "    \"mps\" if torch.backends.mps.is_available() else\n",
    "    \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class ConvNeuralNetwork(nn.Module):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super().__init__()\n",
    "        self.conv_stack = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_stack = nn.Sequential(\n",
    "            nn.Linear(32 * 8 * 8, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_stack(x)\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = ConvNeuralNetwork().to(device)\n",
    "print(model)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training function\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if batch % 5 == 0:\n",
    "            print(f\"loss: {loss.item():>7f}  [{(batch + 1) * len(X):>5d}/{size:>5d}]\")\n",
    "\n",
    "# Validation/test function\n",
    "def evaluate(dataloader, model, loss_fn, dataset_name=\"Validation\"):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"{dataset_name} Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return correct\n",
    "\n",
    "# Training loop with early stopping\n",
    "best_accuracy = 0.0\n",
    "patience = 5\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    accuracy = evaluate(val_dataloader, model, loss_fn, \"Validation\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print(f\"Saved best model to {model_path} (Validation Accuracy: {100*accuracy:.1f}%)\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "print(\"Training complete!\")\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"Evaluating on test set:\")\n",
    "model.load_state_dict(torch.load(model_path, map_location=device, weights_only=True))\n",
    "evaluate(test_dataloader, model, loss_fn, \"Test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
